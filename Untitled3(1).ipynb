{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n71ydAAlv7xt",
        "outputId": "0f428f08-e7ff-4098-fd36-ef64d4da331a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 2071M  100 2071M    0     0  83.4M      0  0:00:24  0:00:24 --:--:-- 94.0M\n"
          ]
        }
      ],
      "source": [
        "!curl -L -o /content/dataset-mini-mmctr-challenge.zip\\\n",
        "  https://www.kaggle.com/api/v1/datasets/download/othmanehana/dataset-mini-mmctr-challenge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wXbdbO4Uwe03"
      },
      "outputs": [],
      "source": [
        "!unzip /content/dataset-mini-mmctr-challenge.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qYSNCQrSwuh_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ibHtv6UrufxB"
      },
      "outputs": [],
      "source": [
        "item_emb_file = \"/content/Data/item_emb.parquet\"\n",
        "item_feature_file = \"/content/Data/item_feature.parquet\"\n",
        "item_info_file = \"/content/Data/item_info.parquet\"\n",
        "item_seq_file = \"/content/Data/item_seq.parquet\"\n",
        "test_file = \"/content/Data/test.parquet\"\n",
        "train_file = \"/content/Data/train.parquet\"\n",
        "valid_file = \"/content/Data/valid.parquet\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ExirBnJlvId9"
      },
      "outputs": [],
      "source": [
        "item_emb_df = pd.read_parquet(item_emb_file)\n",
        "item_feature_df = pd.read_parquet(item_feature_file)\n",
        "item_info_df = pd.read_parquet(item_info_file)\n",
        "item_seq_df = pd.read_parquet(item_seq_file)\n",
        "test_df = pd.read_parquet(test_file)\n",
        "train_df = pd.read_parquet(train_file)\n",
        "valid_df = pd.read_parquet(valid_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ktW9CheLlAQ8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class CTRDataset(Dataset):\n",
        "    def __init__(self, data_df, item_embedding_matrix, max_len=50, is_test=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_df (pd.DataFrame): The dataframe containing 'item_seq', 'item_id', 'label'\n",
        "            item_embedding_matrix (torch.Tensor): A tensor of shape (num_items, 128)\n",
        "                                                  where row N is the vector for Item ID N.\n",
        "            max_len (int): Maximum length of user history sequence.\n",
        "            is_test (bool): If True, does not look for 'label'.\n",
        "        \"\"\"\n",
        "        self.data_df = data_df\n",
        "        self.item_embedding_matrix = item_embedding_matrix\n",
        "        self.max_len = max_len\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 1. Get the row\n",
        "        row = self.data_df.iloc[idx]\n",
        "\n",
        "        # 2. Get the Sequence (History)\n",
        "        seq_ids = row['item_seq']\n",
        "\n",
        "        # 3. Handle Padding / Truncation\n",
        "        seq_len = len(seq_ids)\n",
        "\n",
        "        if seq_len < self.max_len:\n",
        "            pads = [0] * (self.max_len - seq_len)\n",
        "            seq_ids = pads + seq_ids\n",
        "        else:\n",
        "            seq_ids = seq_ids[-self.max_len:]\n",
        "\n",
        "        # 4. Convert IDs to Vectors (The Lookup)\n",
        "        seq_tensor = torch.tensor(seq_ids, dtype=torch.long)\n",
        "        history_emb = self.item_embedding_matrix[seq_tensor]\n",
        "\n",
        "        # 5. Get Target Item Vector\n",
        "        target_id = row['item_id']\n",
        "        target_emb = self.item_embedding_matrix[target_id]\n",
        "        likes = torch.tensor(row['likes_level'], dtype=torch.long)\n",
        "        views = torch.tensor(row['views_level'], dtype=torch.long)\n",
        "        user  = torch.tensor(row['user_id'], dtype=torch.long)\n",
        "\n",
        "        # 6. Return Data\n",
        "        output = {\n",
        "            'history_ids': seq_tensor,\n",
        "            'history_emb': history_emb,\n",
        "            'target_id':   torch.tensor(row['item_id'], dtype=torch.long),\n",
        "            'target_emb':  target_emb,\n",
        "            'likes':       likes,\n",
        "            'views':       views,\n",
        "            #'label':       label\n",
        "        }\n",
        "\n",
        "        if not self.is_test:\n",
        "            output['label'] = torch.tensor(row['label'], dtype=torch.float32)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OUHw27hemvi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de212bc-8d2a-41af-a9a0-36c85f5e3639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total items: 45858. Matrix size: 45859\n",
            "Embedding Tensor created successfully!\n",
            "Remapping Train Data...\n",
            "Remapping Valid Data...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# 1. Create a mapping from Raw Item ID -> Matrix Index\n",
        "# We start at index 1 because index 0 is reserved for Padding\n",
        "unique_items = item_emb_df['item_id'].unique()\n",
        "item_id_map = {raw_id: i + 1 for i, raw_id in enumerate(unique_items)}\n",
        "vocab_size = len(unique_items) + 1 # +1 for padding at index 0\n",
        "\n",
        "print(f\"Total items: {len(unique_items)}. Matrix size: {vocab_size}\")\n",
        "\n",
        "# 2. Build the Embedding Tensor\n",
        "# Initialize with zeros (Row 0 remains zero for padding)\n",
        "embedding_matrix = np.zeros((vocab_size, 128), dtype=np.float32)\n",
        "\n",
        "# Fill the matrix\n",
        "# We assume 'item_emb_d128_e4' contains lists or numpy arrays\n",
        "for _, row in item_emb_df.iterrows():\n",
        "    idx = item_id_map.get(row['item_id'])\n",
        "    if idx is not None:\n",
        "        embedding_matrix[idx] = row['item_emb_d128_e4']\n",
        "\n",
        "# Convert to Torch Tensor (Ready for the Dataset Class)\n",
        "embedding_tensor = torch.tensor(embedding_matrix)\n",
        "print(\"Embedding Tensor created successfully!\")\n",
        "\n",
        "# 3. Helper function to remap your Train/Test Dataframes\n",
        "def remap_dataframe(df, mapping):\n",
        "    # Map the target item_id\n",
        "    # If an ID is missing (not in map), set to 0 (Padding/Unknown)\n",
        "    df['mapped_item_id'] = df['item_id'].apply(lambda x: mapping.get(x, 0))\n",
        "\n",
        "    # Map the sequence\n",
        "    # This might take a moment on CPU\n",
        "    def map_seq(seq):\n",
        "        return [mapping.get(x, 0) for x in seq]\n",
        "\n",
        "    df['mapped_item_seq'] = df['item_seq'].apply(map_seq)\n",
        "    return df\n",
        "\n",
        "# APPLY THE MAPPING (Assumes you have train_df and valid_df loaded)\n",
        "print(\"Remapping Train Data...\")\n",
        "train_df = remap_dataframe(train_df, item_id_map)\n",
        "print(\"Remapping Valid Data...\")\n",
        "valid_df = remap_dataframe(valid_df, item_id_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7RAMJk3PxmCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8850e763-a1fc-40ad-eab9-768de7018c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Running on: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class HybridCTRTransformer(nn.Module):\n",
        "    def __init__(self, num_items, pretrained_dim=128, model_dim=128, num_heads=4, num_layers=2):\n",
        "        \"\"\"\n",
        "        num_items: Total number of unique items (vocab_size)\n",
        "        pretrained_dim: Dimension of your parquet vectors (128)\n",
        "        model_dim: Dimension we want to use inside the Transformer\n",
        "        \"\"\"\n",
        "        super(HybridCTRTransformer, self).__init__()\n",
        "\n",
        "        # --- BLOCK 1: The Hybrid Embedding Layer ---\n",
        "        # A. Learnable ID Embedding (The \"Memory\")\n",
        "        # Padding index 0 will remain 0\n",
        "        self.item_id_embedding = nn.Embedding(num_items, model_dim, padding_idx=0)\n",
        "\n",
        "        # B. Content Adapter (The \"Interpreter\")\n",
        "        # Takes the fixed BERT/ResNet vector and learns how to use it for CTR\n",
        "        self.content_adapter = nn.Linear(pretrained_dim, model_dim)\n",
        "\n",
        "        # --- BLOCK 2: The Transformer ---\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, 50, model_dim))\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=model_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=model_dim*4,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # --- BLOCK 3: Static Features ---\n",
        "        self.likes_emb = nn.Embedding(20, 32)\n",
        "        self.views_emb = nn.Embedding(20, 32)\n",
        "\n",
        "        # --- BLOCK 4: The Prediction Head ---\n",
        "        # Input: User_Interest(128) + Target_Item(128) + Likes(32) + Views(32) = 320\n",
        "        total_dim = model_dim * 2 + 32 + 32\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(total_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def get_full_representation(self, item_ids, content_vecs):\n",
        "        \"\"\"\n",
        "        Helper to combine ID and Content\n",
        "        \"\"\"\n",
        "        # 1. Get ID embedding\n",
        "        id_vec = self.item_id_embedding(item_ids) # (Batch, Seq, 128)\n",
        "\n",
        "        # 2. Get Adapted Content embedding\n",
        "        content_vec = self.content_adapter(content_vecs) # (Batch, Seq, 128)\n",
        "\n",
        "        # 3. Sum them up\n",
        "        return id_vec + content_vec\n",
        "\n",
        "    def forward(self, history_ids, history_content, target_id, target_content, likes, views):\n",
        "        # --- Step 1: Create Representations ---\n",
        "        # Use the helper to fuse ID + Content for both History and Target\n",
        "\n",
        "        # History Sequence\n",
        "        history_x = self.get_full_representation(history_ids, history_content)\n",
        "\n",
        "        # Target Item\n",
        "        target_x = self.get_full_representation(target_id, target_content)\n",
        "\n",
        "        # --- Step 2: Transformer on History ---\n",
        "        # Add position info\n",
        "        x = history_x + self.pos_embedding\n",
        "\n",
        "        # Pass through Transformer\n",
        "        # We should strictly use a padding mask here, but for now we rely on the\n",
        "        # embedding of '0' being learned as \"ignore me\" or zero.\n",
        "        transformer_out = self.transformer(x)\n",
        "\n",
        "        # Take the last item as User Interest\n",
        "        user_interest = transformer_out[:, -1, :]\n",
        "\n",
        "        # --- Step 3: Static Features ---\n",
        "        like_vec = self.likes_emb(likes)\n",
        "        view_vec = self.views_emb(views)\n",
        "\n",
        "        # --- Step 4: Concatenate & Predict ---\n",
        "        combined = torch.cat([user_interest, target_x, like_vec, view_vec], dim=1)\n",
        "\n",
        "        logits = self.mlp(combined)\n",
        "        return self.sigmoid(logits)"
      ],
      "metadata": {
        "id": "pP_6mpDBL3LX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MpHkroooA86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0135da7-e6eb-4cb1-ced6-049e9d39fcba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training on cuda...\n",
            "Epoch 1 | Batch 0 | Loss: 0.7006\n",
            "Epoch 1 | Batch 50 | Loss: 0.5486\n",
            "Epoch 1 | Batch 100 | Loss: 0.5631\n",
            "Epoch 1 | Batch 150 | Loss: 0.5230\n",
            "Epoch 1 | Batch 200 | Loss: 0.5656\n",
            "Epoch 1 | Batch 250 | Loss: 0.5706\n",
            "Epoch 1 | Batch 300 | Loss: 0.5328\n",
            "Epoch 1 | Batch 350 | Loss: 0.5289\n",
            "Epoch 1 | Batch 400 | Loss: 0.4918\n",
            "Epoch 1 | Batch 450 | Loss: 0.5245\n",
            "Epoch 1 | Batch 500 | Loss: 0.5052\n",
            "Epoch 1 | Batch 550 | Loss: 0.4909\n",
            "Epoch 1 | Batch 600 | Loss: 0.4648\n",
            "Epoch 1 | Batch 650 | Loss: 0.4636\n",
            "Epoch 1 | Batch 700 | Loss: 0.4692\n",
            "Epoch 1 | Batch 750 | Loss: 0.4821\n",
            "Epoch 1 | Batch 800 | Loss: 0.4016\n",
            "Epoch 1 | Batch 850 | Loss: 0.4201\n",
            "Epoch 1 | Batch 900 | Loss: 0.4328\n",
            "Epoch 1 | Batch 950 | Loss: 0.4457\n",
            "Epoch 1 | Batch 1000 | Loss: 0.4173\n",
            "Epoch 1 | Batch 1050 | Loss: 0.4018\n",
            "Epoch 1 | Batch 1100 | Loss: 0.4080\n",
            "Epoch 1 | Batch 1150 | Loss: 0.4111\n",
            "Epoch 1 | Batch 1200 | Loss: 0.4386\n",
            "Epoch 1 | Batch 1250 | Loss: 0.4215\n",
            "Epoch 1 | Batch 1300 | Loss: 0.4036\n",
            "Epoch 1 | Batch 1350 | Loss: 0.3988\n",
            "Epoch 1 | Batch 1400 | Loss: 0.4468\n",
            "Epoch 1 | Batch 1450 | Loss: 0.3688\n",
            "Epoch 1 | Batch 1500 | Loss: 0.4156\n",
            "Epoch 1 | Batch 1550 | Loss: 0.3845\n",
            "Epoch 1 | Batch 1600 | Loss: 0.3835\n",
            "Epoch 1 | Batch 1650 | Loss: 0.4288\n",
            "Epoch 1 | Batch 1700 | Loss: 0.3956\n",
            "Epoch 1 | Batch 1750 | Loss: 0.3918\n",
            "Epoch 1 Complete! Average Training Loss: 0.4566\n",
            "Validation AUC: 0.5591\n",
            "Epoch 2 | Batch 0 | Loss: 0.3785\n",
            "Epoch 2 | Batch 50 | Loss: 0.4033\n",
            "Epoch 2 | Batch 100 | Loss: 0.3692\n",
            "Epoch 2 | Batch 150 | Loss: 0.3526\n",
            "Epoch 2 | Batch 200 | Loss: 0.3720\n",
            "Epoch 2 | Batch 250 | Loss: 0.3880\n",
            "Epoch 2 | Batch 300 | Loss: 0.4080\n",
            "Epoch 2 | Batch 350 | Loss: 0.3841\n",
            "Epoch 2 | Batch 400 | Loss: 0.3921\n",
            "Epoch 2 | Batch 450 | Loss: 0.3776\n",
            "Epoch 2 | Batch 500 | Loss: 0.4017\n",
            "Epoch 2 | Batch 550 | Loss: 0.3701\n",
            "Epoch 2 | Batch 600 | Loss: 0.3998\n",
            "Epoch 2 | Batch 650 | Loss: 0.3460\n",
            "Epoch 2 | Batch 700 | Loss: 0.3463\n",
            "Epoch 2 | Batch 750 | Loss: 0.3662\n",
            "Epoch 2 | Batch 800 | Loss: 0.3768\n",
            "Epoch 2 | Batch 850 | Loss: 0.3543\n",
            "Epoch 2 | Batch 900 | Loss: 0.3912\n",
            "Epoch 2 | Batch 950 | Loss: 0.3684\n",
            "Epoch 2 | Batch 1000 | Loss: 0.3688\n",
            "Epoch 2 | Batch 1050 | Loss: 0.3691\n",
            "Epoch 2 | Batch 1100 | Loss: 0.3557\n",
            "Epoch 2 | Batch 1150 | Loss: 0.3615\n",
            "Epoch 2 | Batch 1200 | Loss: 0.3853\n",
            "Epoch 2 | Batch 1250 | Loss: 0.3866\n",
            "Epoch 2 | Batch 1300 | Loss: 0.3624\n",
            "Epoch 2 | Batch 1350 | Loss: 0.3614\n",
            "Epoch 2 | Batch 1400 | Loss: 0.3568\n",
            "Epoch 2 | Batch 1450 | Loss: 0.3919\n",
            "Epoch 2 | Batch 1500 | Loss: 0.3758\n",
            "Epoch 2 | Batch 1550 | Loss: 0.3727\n",
            "Epoch 2 | Batch 1600 | Loss: 0.3782\n",
            "Epoch 2 | Batch 1650 | Loss: 0.3544\n",
            "Epoch 2 | Batch 1700 | Loss: 0.3623\n",
            "Epoch 2 | Batch 1750 | Loss: 0.3522\n",
            "Epoch 2 Complete! Average Training Loss: 0.3719\n",
            "Validation AUC: 0.5876\n",
            "Epoch 3 | Batch 0 | Loss: 0.3480\n",
            "Epoch 3 | Batch 50 | Loss: 0.3518\n",
            "Epoch 3 | Batch 100 | Loss: 0.3433\n",
            "Epoch 3 | Batch 150 | Loss: 0.3471\n",
            "Epoch 3 | Batch 200 | Loss: 0.3494\n",
            "Epoch 3 | Batch 250 | Loss: 0.3296\n",
            "Epoch 3 | Batch 300 | Loss: 0.3824\n",
            "Epoch 3 | Batch 350 | Loss: 0.3161\n",
            "Epoch 3 | Batch 400 | Loss: 0.3660\n",
            "Epoch 3 | Batch 450 | Loss: 0.3682\n",
            "Epoch 3 | Batch 500 | Loss: 0.3420\n",
            "Epoch 3 | Batch 550 | Loss: 0.3232\n",
            "Epoch 3 | Batch 600 | Loss: 0.3431\n",
            "Epoch 3 | Batch 650 | Loss: 0.3442\n",
            "Epoch 3 | Batch 700 | Loss: 0.3649\n",
            "Epoch 3 | Batch 750 | Loss: 0.3348\n",
            "Epoch 3 | Batch 800 | Loss: 0.3375\n",
            "Epoch 3 | Batch 850 | Loss: 0.3479\n",
            "Epoch 3 | Batch 900 | Loss: 0.3426\n",
            "Epoch 3 | Batch 950 | Loss: 0.3420\n",
            "Epoch 3 | Batch 1000 | Loss: 0.3438\n",
            "Epoch 3 | Batch 1050 | Loss: 0.3380\n",
            "Epoch 3 | Batch 1100 | Loss: 0.3582\n",
            "Epoch 3 | Batch 1150 | Loss: 0.3077\n",
            "Epoch 3 | Batch 1200 | Loss: 0.3331\n",
            "Epoch 3 | Batch 1250 | Loss: 0.3354\n",
            "Epoch 3 | Batch 1300 | Loss: 0.3685\n",
            "Epoch 3 | Batch 1350 | Loss: 0.3614\n",
            "Epoch 3 | Batch 1400 | Loss: 0.3694\n",
            "Epoch 3 | Batch 1450 | Loss: 0.3442\n",
            "Epoch 3 | Batch 1500 | Loss: 0.3257\n",
            "Epoch 3 | Batch 1550 | Loss: 0.3589\n",
            "Epoch 3 | Batch 1600 | Loss: 0.3306\n",
            "Epoch 3 | Batch 1650 | Loss: 0.3353\n",
            "Epoch 3 | Batch 1700 | Loss: 0.3304\n",
            "Epoch 3 | Batch 1750 | Loss: 0.3240\n",
            "Epoch 3 Complete! Average Training Loss: 0.3480\n",
            "Validation AUC: 0.6111\n",
            "Epoch 4 | Batch 0 | Loss: 0.3395\n",
            "Epoch 4 | Batch 50 | Loss: 0.3322\n",
            "Epoch 4 | Batch 100 | Loss: 0.3556\n",
            "Epoch 4 | Batch 150 | Loss: 0.3208\n",
            "Epoch 4 | Batch 200 | Loss: 0.3347\n",
            "Epoch 4 | Batch 250 | Loss: 0.3472\n",
            "Epoch 4 | Batch 300 | Loss: 0.3181\n",
            "Epoch 4 | Batch 350 | Loss: 0.3347\n",
            "Epoch 4 | Batch 400 | Loss: 0.3330\n",
            "Epoch 4 | Batch 450 | Loss: 0.3476\n",
            "Epoch 4 | Batch 500 | Loss: 0.3256\n",
            "Epoch 4 | Batch 550 | Loss: 0.3255\n",
            "Epoch 4 | Batch 600 | Loss: 0.3410\n",
            "Epoch 4 | Batch 650 | Loss: 0.3341\n",
            "Epoch 4 | Batch 700 | Loss: 0.3336\n",
            "Epoch 4 | Batch 750 | Loss: 0.3247\n",
            "Epoch 4 | Batch 800 | Loss: 0.3358\n",
            "Epoch 4 | Batch 850 | Loss: 0.3442\n",
            "Epoch 4 | Batch 900 | Loss: 0.3421\n",
            "Epoch 4 | Batch 950 | Loss: 0.3490\n",
            "Epoch 4 | Batch 1000 | Loss: 0.3206\n",
            "Epoch 4 | Batch 1050 | Loss: 0.3424\n",
            "Epoch 4 | Batch 1100 | Loss: 0.3213\n",
            "Epoch 4 | Batch 1150 | Loss: 0.3395\n",
            "Epoch 4 | Batch 1200 | Loss: 0.3252\n",
            "Epoch 4 | Batch 1250 | Loss: 0.3456\n",
            "Epoch 4 | Batch 1300 | Loss: 0.3297\n",
            "Epoch 4 | Batch 1350 | Loss: 0.3445\n",
            "Epoch 4 | Batch 1400 | Loss: 0.3254\n",
            "Epoch 4 | Batch 1450 | Loss: 0.3407\n",
            "Epoch 4 | Batch 1500 | Loss: 0.3079\n",
            "Epoch 4 | Batch 1550 | Loss: 0.3361\n",
            "Epoch 4 | Batch 1600 | Loss: 0.3323\n",
            "Epoch 4 | Batch 1650 | Loss: 0.3100\n",
            "Epoch 4 | Batch 1700 | Loss: 0.3151\n",
            "Epoch 4 | Batch 1750 | Loss: 0.3385\n",
            "Epoch 4 Complete! Average Training Loss: 0.3342\n",
            "Validation AUC: 0.6263\n",
            "Epoch 5 | Batch 0 | Loss: 0.3363\n",
            "Epoch 5 | Batch 50 | Loss: 0.3233\n",
            "Epoch 5 | Batch 100 | Loss: 0.3345\n",
            "Epoch 5 | Batch 150 | Loss: 0.3094\n",
            "Epoch 5 | Batch 200 | Loss: 0.3214\n",
            "Epoch 5 | Batch 250 | Loss: 0.3222\n",
            "Epoch 5 | Batch 300 | Loss: 0.3150\n",
            "Epoch 5 | Batch 350 | Loss: 0.3118\n",
            "Epoch 5 | Batch 400 | Loss: 0.3034\n",
            "Epoch 5 | Batch 450 | Loss: 0.3240\n",
            "Epoch 5 | Batch 500 | Loss: 0.3295\n",
            "Epoch 5 | Batch 550 | Loss: 0.3405\n",
            "Epoch 5 | Batch 600 | Loss: 0.3221\n",
            "Epoch 5 | Batch 650 | Loss: 0.2843\n",
            "Epoch 5 | Batch 700 | Loss: 0.3159\n",
            "Epoch 5 | Batch 750 | Loss: 0.3367\n",
            "Epoch 5 | Batch 800 | Loss: 0.3093\n",
            "Epoch 5 | Batch 850 | Loss: 0.3350\n",
            "Epoch 5 | Batch 900 | Loss: 0.3427\n",
            "Epoch 5 | Batch 950 | Loss: 0.3310\n",
            "Epoch 5 | Batch 1000 | Loss: 0.3341\n",
            "Epoch 5 | Batch 1050 | Loss: 0.3258\n",
            "Epoch 5 | Batch 1100 | Loss: 0.2741\n",
            "Epoch 5 | Batch 1150 | Loss: 0.3139\n",
            "Epoch 5 | Batch 1200 | Loss: 0.3433\n",
            "Epoch 5 | Batch 1250 | Loss: 0.3175\n",
            "Epoch 5 | Batch 1300 | Loss: 0.2972\n",
            "Epoch 5 | Batch 1350 | Loss: 0.3062\n",
            "Epoch 5 | Batch 1400 | Loss: 0.3258\n",
            "Epoch 5 | Batch 1450 | Loss: 0.3533\n",
            "Epoch 5 | Batch 1500 | Loss: 0.2936\n",
            "Epoch 5 | Batch 1550 | Loss: 0.3298\n",
            "Epoch 5 | Batch 1600 | Loss: 0.3245\n",
            "Epoch 5 | Batch 1650 | Loss: 0.3327\n",
            "Epoch 5 | Batch 1700 | Loss: 0.3121\n",
            "Epoch 5 | Batch 1750 | Loss: 0.3004\n",
            "Epoch 5 Complete! Average Training Loss: 0.3249\n",
            "Validation AUC: 0.6441\n",
            "Epoch 6 | Batch 0 | Loss: 0.3190\n",
            "Epoch 6 | Batch 50 | Loss: 0.3197\n",
            "Epoch 6 | Batch 100 | Loss: 0.3521\n",
            "Epoch 6 | Batch 150 | Loss: 0.2947\n",
            "Epoch 6 | Batch 200 | Loss: 0.3358\n",
            "Epoch 6 | Batch 250 | Loss: 0.3239\n",
            "Epoch 6 | Batch 300 | Loss: 0.3441\n",
            "Epoch 6 | Batch 350 | Loss: 0.3419\n",
            "Epoch 6 | Batch 400 | Loss: 0.2935\n",
            "Epoch 6 | Batch 450 | Loss: 0.3261\n",
            "Epoch 6 | Batch 500 | Loss: 0.3401\n",
            "Epoch 6 | Batch 550 | Loss: 0.3196\n",
            "Epoch 6 | Batch 600 | Loss: 0.3136\n",
            "Epoch 6 | Batch 650 | Loss: 0.2822\n",
            "Epoch 6 | Batch 700 | Loss: 0.3191\n",
            "Epoch 6 | Batch 750 | Loss: 0.3426\n",
            "Epoch 6 | Batch 800 | Loss: 0.3208\n",
            "Epoch 6 | Batch 850 | Loss: 0.3059\n",
            "Epoch 6 | Batch 900 | Loss: 0.3027\n",
            "Epoch 6 | Batch 950 | Loss: 0.3136\n",
            "Epoch 6 | Batch 1000 | Loss: 0.3404\n",
            "Epoch 6 | Batch 1050 | Loss: 0.3097\n",
            "Epoch 6 | Batch 1100 | Loss: 0.3040\n",
            "Epoch 6 | Batch 1150 | Loss: 0.3390\n",
            "Epoch 6 | Batch 1200 | Loss: 0.3290\n",
            "Epoch 6 | Batch 1250 | Loss: 0.3214\n",
            "Epoch 6 | Batch 1300 | Loss: 0.3166\n",
            "Epoch 6 | Batch 1350 | Loss: 0.3049\n",
            "Epoch 6 | Batch 1400 | Loss: 0.3109\n",
            "Epoch 6 | Batch 1450 | Loss: 0.3039\n",
            "Epoch 6 | Batch 1500 | Loss: 0.3135\n",
            "Epoch 6 | Batch 1550 | Loss: 0.3472\n",
            "Epoch 6 | Batch 1600 | Loss: 0.3282\n",
            "Epoch 6 | Batch 1650 | Loss: 0.3319\n",
            "Epoch 6 | Batch 1700 | Loss: 0.3067\n",
            "Epoch 6 | Batch 1750 | Loss: 0.3174\n",
            "Epoch 6 Complete! Average Training Loss: 0.3184\n",
            "Validation AUC: 0.6455\n",
            "Epoch 7 | Batch 0 | Loss: 0.2969\n",
            "Epoch 7 | Batch 50 | Loss: 0.3243\n",
            "Epoch 7 | Batch 100 | Loss: 0.3104\n",
            "Epoch 7 | Batch 150 | Loss: 0.3200\n",
            "Epoch 7 | Batch 200 | Loss: 0.2979\n",
            "Epoch 7 | Batch 250 | Loss: 0.2960\n",
            "Epoch 7 | Batch 300 | Loss: 0.3199\n",
            "Epoch 7 | Batch 350 | Loss: 0.3146\n",
            "Epoch 7 | Batch 400 | Loss: 0.3187\n",
            "Epoch 7 | Batch 450 | Loss: 0.3098\n",
            "Epoch 7 | Batch 500 | Loss: 0.3077\n",
            "Epoch 7 | Batch 550 | Loss: 0.2959\n",
            "Epoch 7 | Batch 600 | Loss: 0.3288\n",
            "Epoch 7 | Batch 650 | Loss: 0.3148\n",
            "Epoch 7 | Batch 700 | Loss: 0.3316\n",
            "Epoch 7 | Batch 750 | Loss: 0.3509\n",
            "Epoch 7 | Batch 800 | Loss: 0.3047\n",
            "Epoch 7 | Batch 850 | Loss: 0.2997\n",
            "Epoch 7 | Batch 900 | Loss: 0.3059\n",
            "Epoch 7 | Batch 950 | Loss: 0.3144\n",
            "Epoch 7 | Batch 1000 | Loss: 0.3116\n",
            "Epoch 7 | Batch 1050 | Loss: 0.3056\n",
            "Epoch 7 | Batch 1100 | Loss: 0.3157\n",
            "Epoch 7 | Batch 1150 | Loss: 0.3062\n",
            "Epoch 7 | Batch 1200 | Loss: 0.2906\n",
            "Epoch 7 | Batch 1250 | Loss: 0.3109\n",
            "Epoch 7 | Batch 1300 | Loss: 0.2981\n",
            "Epoch 7 | Batch 1350 | Loss: 0.3083\n",
            "Epoch 7 | Batch 1400 | Loss: 0.3220\n",
            "Epoch 7 | Batch 1450 | Loss: 0.2863\n",
            "Epoch 7 | Batch 1500 | Loss: 0.3063\n",
            "Epoch 7 | Batch 1550 | Loss: 0.3329\n",
            "Epoch 7 | Batch 1600 | Loss: 0.3331\n",
            "Epoch 7 | Batch 1650 | Loss: 0.3306\n",
            "Epoch 7 | Batch 1700 | Loss: 0.3001\n",
            "Epoch 7 | Batch 1750 | Loss: 0.3016\n",
            "Epoch 7 Complete! Average Training Loss: 0.3135\n",
            "Validation AUC: 0.6553\n",
            "Epoch 8 | Batch 0 | Loss: 0.3060\n",
            "Epoch 8 | Batch 50 | Loss: 0.3144\n",
            "Epoch 8 | Batch 100 | Loss: 0.3066\n",
            "Epoch 8 | Batch 150 | Loss: 0.3021\n",
            "Epoch 8 | Batch 200 | Loss: 0.2996\n",
            "Epoch 8 | Batch 250 | Loss: 0.3377\n",
            "Epoch 8 | Batch 300 | Loss: 0.3052\n",
            "Epoch 8 | Batch 350 | Loss: 0.2993\n",
            "Epoch 8 | Batch 400 | Loss: 0.3078\n",
            "Epoch 8 | Batch 450 | Loss: 0.3072\n",
            "Epoch 8 | Batch 500 | Loss: 0.3104\n",
            "Epoch 8 | Batch 550 | Loss: 0.2872\n",
            "Epoch 8 | Batch 600 | Loss: 0.2692\n",
            "Epoch 8 | Batch 650 | Loss: 0.3045\n",
            "Epoch 8 | Batch 700 | Loss: 0.3319\n",
            "Epoch 8 | Batch 750 | Loss: 0.3218\n",
            "Epoch 8 | Batch 800 | Loss: 0.2969\n",
            "Epoch 8 | Batch 850 | Loss: 0.3137\n",
            "Epoch 8 | Batch 900 | Loss: 0.3267\n",
            "Epoch 8 | Batch 950 | Loss: 0.3441\n",
            "Epoch 8 | Batch 1000 | Loss: 0.3210\n",
            "Epoch 8 | Batch 1050 | Loss: 0.3033\n",
            "Epoch 8 | Batch 1100 | Loss: 0.3449\n",
            "Epoch 8 | Batch 1150 | Loss: 0.3200\n",
            "Epoch 8 | Batch 1200 | Loss: 0.3088\n",
            "Epoch 8 | Batch 1250 | Loss: 0.3080\n",
            "Epoch 8 | Batch 1300 | Loss: 0.3204\n",
            "Epoch 8 | Batch 1350 | Loss: 0.3474\n",
            "Epoch 8 | Batch 1400 | Loss: 0.3062\n",
            "Epoch 8 | Batch 1450 | Loss: 0.3087\n",
            "Epoch 8 | Batch 1500 | Loss: 0.2996\n",
            "Epoch 8 | Batch 1550 | Loss: 0.3393\n",
            "Epoch 8 | Batch 1600 | Loss: 0.3143\n",
            "Epoch 8 | Batch 1650 | Loss: 0.3216\n",
            "Epoch 8 | Batch 1700 | Loss: 0.3170\n",
            "Epoch 8 | Batch 1750 | Loss: 0.3205\n",
            "Epoch 8 Complete! Average Training Loss: 0.3099\n",
            "Validation AUC: 0.6519\n",
            "Epoch 9 | Batch 0 | Loss: 0.2837\n",
            "Epoch 9 | Batch 50 | Loss: 0.3061\n",
            "Epoch 9 | Batch 100 | Loss: 0.2994\n",
            "Epoch 9 | Batch 150 | Loss: 0.3275\n",
            "Epoch 9 | Batch 200 | Loss: 0.2955\n",
            "Epoch 9 | Batch 250 | Loss: 0.3008\n",
            "Epoch 9 | Batch 300 | Loss: 0.3335\n",
            "Epoch 9 | Batch 350 | Loss: 0.2913\n",
            "Epoch 9 | Batch 400 | Loss: 0.3095\n",
            "Epoch 9 | Batch 450 | Loss: 0.3021\n",
            "Epoch 9 | Batch 500 | Loss: 0.3004\n",
            "Epoch 9 | Batch 550 | Loss: 0.3294\n",
            "Epoch 9 | Batch 600 | Loss: 0.2640\n",
            "Epoch 9 | Batch 650 | Loss: 0.3324\n",
            "Epoch 9 | Batch 700 | Loss: 0.3084\n",
            "Epoch 9 | Batch 750 | Loss: 0.3220\n",
            "Epoch 9 | Batch 800 | Loss: 0.3056\n",
            "Epoch 9 | Batch 850 | Loss: 0.3006\n",
            "Epoch 9 | Batch 900 | Loss: 0.2938\n",
            "Epoch 9 | Batch 950 | Loss: 0.3102\n",
            "Epoch 9 | Batch 1000 | Loss: 0.3021\n",
            "Epoch 9 | Batch 1050 | Loss: 0.3394\n",
            "Epoch 9 | Batch 1100 | Loss: 0.3224\n",
            "Epoch 9 | Batch 1150 | Loss: 0.3247\n",
            "Epoch 9 | Batch 1200 | Loss: 0.2977\n",
            "Epoch 9 | Batch 1250 | Loss: 0.3297\n",
            "Epoch 9 | Batch 1300 | Loss: 0.3123\n",
            "Epoch 9 | Batch 1350 | Loss: 0.3322\n",
            "Epoch 9 | Batch 1400 | Loss: 0.3104\n",
            "Epoch 9 | Batch 1450 | Loss: 0.3202\n",
            "Epoch 9 | Batch 1500 | Loss: 0.3131\n",
            "Epoch 9 | Batch 1550 | Loss: 0.3023\n",
            "Epoch 9 | Batch 1600 | Loss: 0.3258\n",
            "Epoch 9 | Batch 1650 | Loss: 0.2848\n",
            "Epoch 9 | Batch 1700 | Loss: 0.3156\n",
            "Epoch 9 | Batch 1750 | Loss: 0.2955\n",
            "Epoch 9 Complete! Average Training Loss: 0.3069\n",
            "Validation AUC: 0.6534\n",
            "Epoch 10 | Batch 0 | Loss: 0.2902\n",
            "Epoch 10 | Batch 50 | Loss: 0.3208\n",
            "Epoch 10 | Batch 100 | Loss: 0.3014\n",
            "Epoch 10 | Batch 150 | Loss: 0.3016\n",
            "Epoch 10 | Batch 200 | Loss: 0.2855\n",
            "Epoch 10 | Batch 250 | Loss: 0.2936\n",
            "Epoch 10 | Batch 300 | Loss: 0.3087\n",
            "Epoch 10 | Batch 350 | Loss: 0.3203\n",
            "Epoch 10 | Batch 400 | Loss: 0.3177\n",
            "Epoch 10 | Batch 450 | Loss: 0.3079\n",
            "Epoch 10 | Batch 500 | Loss: 0.3058\n",
            "Epoch 10 | Batch 550 | Loss: 0.3149\n",
            "Epoch 10 | Batch 600 | Loss: 0.2944\n",
            "Epoch 10 | Batch 650 | Loss: 0.2997\n",
            "Epoch 10 | Batch 700 | Loss: 0.3038\n",
            "Epoch 10 | Batch 750 | Loss: 0.3087\n",
            "Epoch 10 | Batch 800 | Loss: 0.2902\n",
            "Epoch 10 | Batch 850 | Loss: 0.3301\n",
            "Epoch 10 | Batch 900 | Loss: 0.2955\n",
            "Epoch 10 | Batch 950 | Loss: 0.2944\n",
            "Epoch 10 | Batch 1000 | Loss: 0.3007\n",
            "Epoch 10 | Batch 1050 | Loss: 0.3044\n",
            "Epoch 10 | Batch 1100 | Loss: 0.3056\n",
            "Epoch 10 | Batch 1150 | Loss: 0.3162\n",
            "Epoch 10 | Batch 1200 | Loss: 0.3038\n",
            "Epoch 10 | Batch 1250 | Loss: 0.2972\n",
            "Epoch 10 | Batch 1300 | Loss: 0.3135\n",
            "Epoch 10 | Batch 1350 | Loss: 0.2922\n",
            "Epoch 10 | Batch 1400 | Loss: 0.3438\n",
            "Epoch 10 | Batch 1450 | Loss: 0.2823\n",
            "Epoch 10 | Batch 1500 | Loss: 0.3281\n",
            "Epoch 10 | Batch 1550 | Loss: 0.2991\n",
            "Epoch 10 | Batch 1600 | Loss: 0.2870\n",
            "Epoch 10 | Batch 1650 | Loss: 0.2964\n",
            "Epoch 10 | Batch 1700 | Loss: 0.2924\n",
            "Epoch 10 | Batch 1750 | Loss: 0.3024\n",
            "Epoch 10 Complete! Average Training Loss: 0.3047\n",
            "Validation AUC: 0.6521\n",
            "Epoch 11 | Batch 0 | Loss: 0.3138\n",
            "Epoch 11 | Batch 50 | Loss: 0.2768\n",
            "Epoch 11 | Batch 100 | Loss: 0.2905\n",
            "Epoch 11 | Batch 150 | Loss: 0.2915\n",
            "Epoch 11 | Batch 200 | Loss: 0.2820\n",
            "Epoch 11 | Batch 250 | Loss: 0.3087\n",
            "Epoch 11 | Batch 300 | Loss: 0.3022\n",
            "Epoch 11 | Batch 350 | Loss: 0.2978\n",
            "Epoch 11 | Batch 400 | Loss: 0.3139\n",
            "Epoch 11 | Batch 450 | Loss: 0.2828\n",
            "Epoch 11 | Batch 500 | Loss: 0.2927\n",
            "Epoch 11 | Batch 550 | Loss: 0.2916\n",
            "Epoch 11 | Batch 600 | Loss: 0.3053\n",
            "Epoch 11 | Batch 650 | Loss: 0.3008\n",
            "Epoch 11 | Batch 700 | Loss: 0.2867\n",
            "Epoch 11 | Batch 750 | Loss: 0.2887\n",
            "Epoch 11 | Batch 800 | Loss: 0.3191\n",
            "Epoch 11 | Batch 850 | Loss: 0.2933\n",
            "Epoch 11 | Batch 900 | Loss: 0.3109\n",
            "Epoch 11 | Batch 950 | Loss: 0.2921\n",
            "Epoch 11 | Batch 1000 | Loss: 0.2987\n",
            "Epoch 11 | Batch 1050 | Loss: 0.2873\n",
            "Epoch 11 | Batch 1100 | Loss: 0.3030\n",
            "Epoch 11 | Batch 1150 | Loss: 0.2864\n",
            "Epoch 11 | Batch 1200 | Loss: 0.2893\n",
            "Epoch 11 | Batch 1250 | Loss: 0.3262\n",
            "Epoch 11 | Batch 1300 | Loss: 0.3287\n",
            "Epoch 11 | Batch 1350 | Loss: 0.2967\n",
            "Epoch 11 | Batch 1400 | Loss: 0.2728\n",
            "Epoch 11 | Batch 1450 | Loss: 0.3122\n",
            "Epoch 11 | Batch 1500 | Loss: 0.3073\n",
            "Epoch 11 | Batch 1550 | Loss: 0.2607\n",
            "Epoch 11 | Batch 1600 | Loss: 0.3070\n",
            "Epoch 11 | Batch 1650 | Loss: 0.3009\n",
            "Epoch 11 | Batch 1700 | Loss: 0.2907\n",
            "Epoch 11 | Batch 1750 | Loss: 0.2947\n",
            "Epoch 11 Complete! Average Training Loss: 0.3025\n",
            "Validation AUC: 0.6571\n",
            "Epoch 12 | Batch 0 | Loss: 0.3210\n",
            "Epoch 12 | Batch 50 | Loss: 0.2844\n",
            "Epoch 12 | Batch 100 | Loss: 0.2981\n",
            "Epoch 12 | Batch 150 | Loss: 0.2977\n",
            "Epoch 12 | Batch 200 | Loss: 0.2932\n",
            "Epoch 12 | Batch 250 | Loss: 0.3061\n",
            "Epoch 12 | Batch 300 | Loss: 0.2883\n",
            "Epoch 12 | Batch 350 | Loss: 0.3196\n",
            "Epoch 12 | Batch 400 | Loss: 0.2906\n",
            "Epoch 12 | Batch 450 | Loss: 0.2860\n",
            "Epoch 12 | Batch 500 | Loss: 0.2955\n",
            "Epoch 12 | Batch 550 | Loss: 0.3146\n",
            "Epoch 12 | Batch 600 | Loss: 0.3184\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "BATCH_SIZE = 1024\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 20\n",
        "\n",
        "\n",
        "train_df['item_seq'] = train_df['mapped_item_seq']\n",
        "train_df['item_id'] = train_df['mapped_item_id']\n",
        "valid_df['item_seq'] = valid_df['mapped_item_seq']\n",
        "valid_df['item_id'] = valid_df['mapped_item_id']\n",
        "\n",
        "train_dataset = CTRDataset(train_df, embedding_tensor)\n",
        "valid_dataset = CTRDataset(valid_df, embedding_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# 2. Initialize Model\n",
        "model = HybridCTRTransformer(num_items=vocab_size, pretrained_dim=128).to(device)\n",
        "criterion = torch.nn.BCELoss() # Binary Cross Entropy\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print(f\"Starting Training on {device}...\")\n",
        "\n",
        "# 3. Training Loop\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train() # Set to training mode\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        # Unpack batch\n",
        "        # IDs (for the Embedding Layer)\n",
        "        hist_ids = batch['history_ids'].to(device)\n",
        "        tgt_id   = batch['target_id'].to(device)\n",
        "\n",
        "        # Content Vectors (for the Linear Adapter)\n",
        "        hist_emb = batch['history_emb'].to(device)\n",
        "        tgt_emb  = batch['target_emb'].to(device)\n",
        "\n",
        "        # Static\n",
        "        likes = batch['likes'].to(device)\n",
        "        views = batch['views'].to(device)\n",
        "\n",
        "        label   = batch['label'].to(device).unsqueeze(1)\n",
        "\n",
        "        # Forward Pass\n",
        "        optimizer.zero_grad()\n",
        "        prediction = model(hist_ids, hist_emb, tgt_id, tgt_emb, likes, views)\n",
        "\n",
        "        # Calculate Loss\n",
        "        loss = criterion(prediction, label)\n",
        "\n",
        "        # Backward Pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Print every 50 batches so you know it's alive\n",
        "        if i % 50 == 0:\n",
        "            print(f\"Epoch {epoch+1} | Batch {i} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1} Complete! Average Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient calculation (saves memory/time)\n",
        "        for batch in valid_loader:\n",
        "            hist_ids = batch['history_ids'].to(device)\n",
        "            tgt_id   = batch['target_id'].to(device)\n",
        "            hist_emb = batch['history_emb'].to(device)\n",
        "            tgt_emb  = batch['target_emb'].to(device)\n",
        "            likes = batch['likes'].to(device)\n",
        "            views = batch['views'].to(device)\n",
        "            label   = batch['label'].to(device).unsqueeze(1)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(hist_ids, hist_emb, tgt_id, tgt_emb, likes, views)\n",
        "\n",
        "\n",
        "            all_preds.extend(preds.squeeze().tolist())\n",
        "            all_labels.extend(label.tolist())\n",
        "\n",
        "    # Calculate AUC\n",
        "    try:\n",
        "        auc = roc_auc_score(all_labels, all_preds)\n",
        "        print(f\"Validation AUC: {auc:.4f}\")\n",
        "    except ValueError:\n",
        "        print(\"Error calculating AUC (Labels might be all 0s or all 1s in batch)\")\n",
        "\n",
        "print(\"Training Finished!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"hybrid_ctr_model.pth\")\n",
        "print(\"Model weights saved successfully.\")"
      ],
      "metadata": {
        "id": "18mD5YHQ5H83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = HybridCTRTransformer(num_items=vocab_size, pretrained_dim=128)\n",
        "model.load_state_dict(torch.load(\"/content/model_parameters(1).pt\", map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADk-hsgAvbMu",
        "outputId": "ba65d915-3637-4790-c1ea-68780e2be0c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model weights\n",
        "torch.save(model.state_dict(), \"/content/model_parameters(1).pt\")"
      ],
      "metadata": {
        "id": "33R10uanl8IT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "360fdf4c-9978-4b7d-a2a7-fc7f321f64f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-66354734.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hybrid_ctr_model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def generate_all_item_embeddings(model, pretrained_embedding_tensor, device):\n",
        "    \"\"\"\n",
        "    Generates the final 128-d vectors for all items using the trained model.\n",
        "    \"\"\"\n",
        "    model.eval() # Set to evaluation mode\n",
        "\n",
        "    # 1. Create a tensor of all Item IDs [0, 1, 2, ... N]\n",
        "    # (pretrained_embedding_tensor shape is [Vocab_Size, 128])\n",
        "    num_items = pretrained_embedding_tensor.shape[0]\n",
        "    all_ids = torch.arange(num_items, dtype=torch.long).to(device)\n",
        "\n",
        "    # 2. Move the pretrained content vectors to the same device\n",
        "    all_content = pretrained_embedding_tensor.to(device)\n",
        "\n",
        "    # 3. Pass through the model's embedding logic\n",
        "    # We do this in a \"no_grad\" block because we are just extracting, not training\n",
        "    with torch.no_grad():\n",
        "        # This calls: ID_Emb(ids) + Linear(content)\n",
        "        final_embeddings = model.get_full_representation(all_ids, all_content)\n",
        "\n",
        "    # 4. Move back to CPU and convert to Numpy\n",
        "    return final_embeddings.cpu().numpy()\n",
        "\n",
        "# --- EXECUTION ---\n",
        "\n",
        "print(\"Generating final learned embeddings...\")\n",
        "# 'embedding_tensor' is the matrix of BERT/RN50 vectors you created in Step 1\n",
        "final_item_vectors = generate_all_item_embeddings(model, embedding_tensor, device)\n",
        "\n",
        "print(f\"Generated vectors shape: {final_item_vectors.shape}\")\n",
        "# Should be (90000+, 128)"
      ],
      "metadata": {
        "id": "RbAz411zRjrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_item_vectors[1]"
      ],
      "metadata": {
        "id": "J0fS63Y6R2E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load the Test Parquet\n",
        "test_df = pd.read_parquet(\"/content/test.parquet\")\n",
        "\n",
        "\n",
        "print(\"Remapping Test Data...\")\n",
        "test_df = remap_dataframe(test_df, item_id_map)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L23AiIKG69VI",
        "outputId": "e12bac82-c827-4076-8792-8977ea8d09d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remapping Test Data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, data_df, item_embedding_matrix, max_len=50):\n",
        "        self.data_df = data_df\n",
        "        self.item_embedding_matrix = item_embedding_matrix\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data_df.iloc[idx]\n",
        "\n",
        "        # 1. Competition ID (Required for CSV)\n",
        "        comp_id = row['ID']\n",
        "\n",
        "        # 2. History Logic\n",
        "        seq_ids = row['mapped_item_seq'] # Uses the mapped column\n",
        "        seq_len = len(seq_ids)\n",
        "        if seq_len < self.max_len:\n",
        "            pads = [0] * (self.max_len - seq_len)\n",
        "            seq_ids = pads + seq_ids\n",
        "        else:\n",
        "            seq_ids = seq_ids[-self.max_len:]\n",
        "\n",
        "        hist_ids = torch.tensor(seq_ids, dtype=torch.long)\n",
        "        hist_emb = self.item_embedding_matrix[hist_ids]\n",
        "\n",
        "        # 3. Target Logic\n",
        "        target_id_int = row['mapped_item_id']\n",
        "        target_id = torch.tensor(target_id_int, dtype=torch.long)\n",
        "        target_emb = self.item_embedding_matrix[target_id]\n",
        "\n",
        "        # 4. Static Logic\n",
        "        likes = torch.tensor(row['likes_level'], dtype=torch.long)\n",
        "        views = torch.tensor(row['views_level'], dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            'comp_id': comp_id,\n",
        "            'history_ids': hist_ids,\n",
        "            'history_emb': hist_emb.float(),\n",
        "            'target_id': target_id,\n",
        "            'target_emb': target_emb.float(),\n",
        "            'likes': likes,\n",
        "            'views': views\n",
        "        }"
      ],
      "metadata": {
        "id": "u5M0FgQt9DbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Loader\n",
        "test_dataset = TestDataset(test_df, embedding_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "model.eval() # Important! Disables Dropout\n",
        "predictions = []\n",
        "ids = []\n",
        "\n",
        "print(\"Starting Inference...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        # Move inputs to GPU\n",
        "        h_ids = batch['history_ids'].to(device)\n",
        "        h_emb = batch['history_emb'].to(device)\n",
        "        t_id  = batch['target_id'].to(device)\n",
        "        t_emb = batch['target_emb'].to(device)\n",
        "        likes = batch['likes'].to(device)\n",
        "        views = batch['views'].to(device)\n",
        "\n",
        "        # Predict\n",
        "        # Output shape is (Batch, 1), we squeeze to get (Batch,)\n",
        "        preds = model(h_ids, h_emb, t_id, t_emb, likes, views).squeeze()\n",
        "\n",
        "        # Store results\n",
        "        predictions.extend(preds.cpu().tolist())\n",
        "        ids.extend(batch['comp_id'].tolist())\n",
        "\n",
        "print(f\"Inference complete. Generated {len(predictions)} predictions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwRHsMUY9SWO",
        "outputId": "39e0e04b-1435-4b3b-ad15-50c37cceefec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Inference...\n",
            "Inference complete. Generated 379142 predictions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame\n",
        "submission_df = pd.DataFrame({\n",
        "    'ID': ids,\n",
        "    'Task1': 0,               # Fill with 0 (Not your task)\n",
        "    'Task2': predictions,     # YOUR PREDICTIONS\n",
        "    'Task1&2': 0              # Fill with 0 (Not your task)\n",
        "})\n",
        "\n",
        "# Sort by ID just to be safe (optional but good practice)\n",
        "submission_df = submission_df.sort_values('ID')\n",
        "\n",
        "# Save to CSV (index=False is critical!)\n",
        "submission_df.to_csv(\"prediction.csv\", index=False)\n",
        "\n",
        "print(\"prediction.csv created! Good luck with the submission!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aKcc9HO9X7L",
        "outputId": "e86041b8-c566-468d-b2b0-f470f4860bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction.csv created! Good luck with the submission!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}